{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset created successfully: UK-OA.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file (Replace with your actual file path)\n",
    "df = pd.read_csv(\"your_local_path/Output_Areas_2021-UK.csv\")\n",
    "\n",
    "# Select only the required columns\n",
    "selected_columns = [\"OA21CD\", \"LAT\", \"LONG\"]\n",
    "new_df = df[selected_columns]\n",
    "\n",
    "# Rename the columns\n",
    "new_df = new_df.rename(columns={\"OA21CD\": \"OA 2021\", \"LAT\": \"Lat\", \"LONG\": \"Long\"})\n",
    "\n",
    "# Save the new dataset\n",
    "new_df.to_csv(\"UK-OA.csv\", index=False)\n",
    "\n",
    "print(\"New dataset created successfully: UK-OA.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset saved to D:/your_local_path/UK-OA-Population.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_datasets(file1, file2, output_file):\n",
    "    # Load the datasets\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "\n",
    "    # Strip column names to remove leading/trailing spaces\n",
    "    df1.columns = df1.columns.str.strip()\n",
    "    df2.columns = df2.columns.str.strip()\n",
    "\n",
    "    # Rename column if necessary\n",
    "    if 'OA 2021' in df1.columns:\n",
    "        df1.rename(columns={'OA 2021': 'OA2021'}, inplace=True)\n",
    "    if 'OA 2021' in df2.columns:\n",
    "        df2.rename(columns={'OA 2021': 'OA2021'}, inplace=True)\n",
    "\n",
    "    # Check if 'OA2021' exists\n",
    "    if 'OA2021' not in df1.columns or 'OA2021' not in df2.columns:\n",
    "        raise KeyError(\"Column 'OA2021' not found in one or both files. Check column names.\")\n",
    "\n",
    "    # Remove any missing values in 'OA2021'\n",
    "    df1.dropna(subset=['OA2021'], inplace=True)\n",
    "    df2.dropna(subset=['OA2021'], inplace=True)\n",
    "\n",
    "    # Merge datasets on 'OA2021'\n",
    "    merged_df = pd.merge(df1, df2, on='OA2021', how='inner')\n",
    "\n",
    "    # Select relevant columns\n",
    "    merged_df = merged_df[['OA2021', 'Lat', 'Long', 'Population']]\n",
    "\n",
    "    # Save the merged dataset\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    print(f\"Merged dataset saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "file1 = \"your_local_path/UK-OA.csv\"\n",
    "file2 = \"your_local_path/Population-OA-2022.csv\"\n",
    "output_file = \"your_local_path/UK-OA-Population.csv\"\n",
    "\n",
    "merge_datasets(file1, file2, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 completed: Litter data processed and saved to litter_processed.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Load litter data (assumes a CSV file with 'latitude' and 'longitude' columns)\n",
    "litter_df = pd.read_csv(\"your_local_path/southampton_data.csv\")  # Change to your actual file\n",
    "\n",
    "# Convert litter data into a GeoDataFrame\n",
    "litter_gdf = gpd.GeoDataFrame(\n",
    "    litter_df, geometry=gpd.points_from_xy(litter_df.long, litter_df.lat), crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Save processed litter data (optional)\n",
    "litter_gdf.to_csv(\"southampton_litter_processed.csv\", index=False)\n",
    "print(\"Step 2 completed: Litter data processed and saved to litter_processed.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 completed: Results saved to southampton_litter_with_OA&Population.csvv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# Load OA and litter data\n",
    "OA_df = pd.read_csv(\"UK-OA-Population.csv\")\n",
    "litter_df = pd.read_csv(\"southampton_litter_processed.csv\")\n",
    "\n",
    "# Convert both to GeoDataFrames\n",
    "OA_gdf = gpd.GeoDataFrame(\n",
    "    OA_df, geometry=gpd.points_from_xy(OA_df.Long, OA_df.Lat), crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# litter_gdf = gpd.GeoDataFrame(\n",
    "#     litter_df, geometry=gpd.points_from_xy(litter_df.long, litter_df.lat), crs=\"EPSG:4326\"\n",
    "# )\n",
    "litter_gdf = gpd.GeoDataFrame(\n",
    "    litter_df, geometry=gpd.points_from_xy(litter_df.category_center_long, litter_df.category_center_lat), crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Step 3: Find the Nearest OA for Each Litter Location\n",
    "def find_nearest_OA(litter_gdf, OA_gdf):\n",
    "    # Convert GeoDataFrames to numpy arrays for efficient spatial indexing\n",
    "    litter_coords = list(zip(litter_gdf.geometry.x, litter_gdf.geometry.y))\n",
    "    OA_coords = list(zip(OA_gdf.geometry.x, OA_gdf.geometry.y))\n",
    "\n",
    "    # Use KDTree for efficient nearest neighbor search\n",
    "    tree = cKDTree(OA_coords)\n",
    "    distances, indices = tree.query(litter_coords, k=1)  # Find the nearest OA\n",
    "\n",
    "    # Add nearest OA to the litter DataFrame\n",
    "    litter_gdf[\"OA2021\"] = OA_gdf.iloc[indices][\"OA2021\"].values\n",
    "    litter_gdf[\"OA_lat\"] = OA_gdf.iloc[indices][\"Lat\"].values\n",
    "    litter_gdf[\"OA_lon\"] = OA_gdf.iloc[indices][\"Long\"].values\n",
    "    litter_gdf[\"Population\"] = OA_gdf.iloc[indices][\"Population\"].values\n",
    "    litter_gdf[\"distance_m\"] = distances * 111320  # Convert degrees to meters\n",
    "\n",
    "    return litter_gdf\n",
    "\n",
    "# Match litter locations to the nearest OA\n",
    "result_gdf = find_nearest_OA(litter_gdf, OA_gdf)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "result_gdf.drop(columns=\"geometry\").to_csv(\"southampton_litter_with_OA&Population.csv\", index=False)\n",
    "print(\"Step 3 completed: Results saved to southampton_litter_with_OA&Population.csvv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset saved to southampton_litter_with_OA-per-Population.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rahim\\AppData\\Local\\Temp\\ipykernel_11292\\2417103227.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unique_counts['litter_per_population'] = unique_counts['OA2021'].map(oa_litter_counts).astype(float) / unique_counts['OA2021'].map(population_map).astype(float)\n",
      "C:\\Users\\Rahim\\AppData\\Local\\Temp\\ipykernel_11292\\2417103227.py:29: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.00447427 0.00518135 0.00310559 ... 0.02205882        nan 0.02205882]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df['OA2021'].isin(unique_counts['OA2021']), 'litter_per_population'] = unique_counts['litter_per_population']\n"
     ]
    }
   ],
   "source": [
    "#################  Litter per Population #################\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def add_litter_count_column(file_path, output_file):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Ensure Population column is numeric\n",
    "    df['Population'] = pd.to_numeric(df['Population'], errors='coerce')\n",
    "    \n",
    "    # Count occurrences of each material category\n",
    "    litter_counts = df.groupby('material_category_by_location')['litterId'].count()\n",
    "    \n",
    "    # Map counts back to the original dataset\n",
    "    df['litter_count_by_category'] = df['material_category_by_location'].map(litter_counts)\n",
    "    \n",
    "    # Count occurrences of litter_count_by_category per OA2021, considering unique material_category_by_location\n",
    "    unique_counts = df.drop_duplicates(subset=['OA2021', 'material_category_by_location'])\n",
    "    oa_litter_counts = unique_counts.groupby('OA2021')['litter_count_by_category'].sum()\n",
    "    \n",
    "    # Map counts back to the original dataset\n",
    "    df['total_litter_by_OA2021'] = df['OA2021'].map(oa_litter_counts)\n",
    "    \n",
    "    # Compute litter per population ratio and ensure only one row per OA2021 gets a value\n",
    "    df['litter_per_population'] = 0  # Default value\n",
    "    population_map = df.drop_duplicates(subset=['OA2021'])[['OA2021', 'Population']].set_index('OA2021')['Population']\n",
    "    unique_counts['litter_per_population'] = unique_counts['OA2021'].map(oa_litter_counts).astype(float) / unique_counts['OA2021'].map(population_map).astype(float)\n",
    "    \n",
    "    # Map back to the original dataframe\n",
    "    df.loc[df['OA2021'].isin(unique_counts['OA2021']), 'litter_per_population'] = unique_counts['litter_per_population']\n",
    "    \n",
    "    # Save the updated dataset\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Updated dataset saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "file_path = 'southampton_litter_with_OA&Population.csv'  # Replace with actual filename\n",
    "output_file = 'southampton_litter_with_OA-per-Population.csv'\n",
    "add_litter_count_column(file_path, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problematic timestamps that could not be converted:\n",
      "[]\n",
      "Updated dataset saved to southampton_litter_with_OA-per-Population-based-year.csv\n",
      "Missing timestamps count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g3/07d8ggrx03ld_fj9md65wkth0000gn/T/ipykernel_89655/3289506877.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unique_counts['litter_per_population'] = unique_counts['OA2021'].map(oa_litter_counts).astype(float) * 1.7 / df['population_times_year']\n",
      "/var/folders/g3/07d8ggrx03ld_fj9md65wkth0000gn/T/ipykernel_89655/3289506877.py:65: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.00760626 0.00880829 0.0052795  ... 0.0375            nan 0.0375    ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df['OA2021'].isin(unique_counts['OA2021']), 'litter_per_population'] = unique_counts['litter_per_population']\n"
     ]
    }
   ],
   "source": [
    "###########   Litter per Population by considering year ##################\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def update_litter_analysis(file_path, output_file):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Ensure Population column is numeric\n",
    "    df['Population'] = pd.to_numeric(df['Population'], errors='coerce')\n",
    "    \n",
    "    # Preserve original timestamp for debugging\n",
    "    df['original_timestamp'] = df['timestamp']\n",
    "    \n",
    "    # Try parsing timestamps with different formats\n",
    "    def parse_timestamp(ts):\n",
    "        try:\n",
    "            return pd.to_datetime(ts, format='%m/%d/%Y %H:%M:%S')  # Try full format\n",
    "        except ValueError:\n",
    "            try:\n",
    "                return pd.to_datetime(ts, format='%m/%d/%Y %H:%M')  # Try without seconds\n",
    "            except ValueError:\n",
    "                return pd.NaT  # If both fail, return NaT\n",
    "    \n",
    "    df['timestamp'] = df['original_timestamp'].apply(parse_timestamp)\n",
    "    \n",
    "    # Identify problematic timestamps before replacement\n",
    "    missing_timestamps = df[df['timestamp'].isna()]['original_timestamp'].unique()\n",
    "    print(\"Problematic timestamps that could not be converted:\")\n",
    "    print(missing_timestamps[:10])  # Print only the first 10 for inspection\n",
    "    \n",
    "    # Fill missing timestamps with 'Unknown' for debugging\n",
    "    df['timestamp'].fillna(\"Unknown\", inplace=True)\n",
    "    \n",
    "    # Extract year where timestamp is valid\n",
    "    df['year'] = pd.to_datetime(df['timestamp'], errors='coerce').dt.year\n",
    "    \n",
    "    # Count occurrences of each material category\n",
    "    litter_counts = df.groupby('material_category_by_location')['litterId'].count()\n",
    "    \n",
    "    # Map counts back to the original dataset\n",
    "    df['litter_count_by_category'] = df['material_category_by_location'].map(litter_counts)\n",
    "    \n",
    "    # Count occurrences of litter_count_by_category per OA2021, considering unique material_category_by_location\n",
    "    unique_counts = df.drop_duplicates(subset=['OA2021', 'material_category_by_location'])\n",
    "    oa_litter_counts = unique_counts.groupby('OA2021')['litter_count_by_category'].sum()\n",
    "    \n",
    "    # Multiply total_litter_by_OA2021 by 1.7\n",
    "    df['total_litter_by_OA2021'] = df['OA2021'].map(oa_litter_counts) * 2.3\n",
    "    \n",
    "    # Count unique years per OA2021\n",
    "    year_counts = df.groupby('OA2021')['year'].nunique()\n",
    "    df['year_count'] = df['OA2021'].map(year_counts)\n",
    "    \n",
    "    # Compute Population * year_count and store in a new column\n",
    "    population_map = df.drop_duplicates(subset=['OA2021'])[['OA2021', 'Population']].set_index('OA2021')['Population']\n",
    "    df['population_times_year'] = df['OA2021'].map(population_map) * df['year_count']\n",
    "    \n",
    "    # Compute litter per population using Population * year_count\n",
    "    df['litter_per_population'] = 0  # Default value\n",
    "    \n",
    "    unique_counts['litter_per_population'] = unique_counts['OA2021'].map(oa_litter_counts).astype(float) * 1.7 / df['population_times_year']\n",
    "    \n",
    "    # Map back to the original dataframe\n",
    "    df.loc[df['OA2021'].isin(unique_counts['OA2021']), 'litter_per_population'] = unique_counts['litter_per_population']\n",
    "    \n",
    "    # Save the updated dataset\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Updated dataset saved to {output_file}\")\n",
    "    \n",
    "    # Debugging: Print missing timestamps count\n",
    "    missing_timestamps_count = df[df['timestamp'] == \"Unknown\"].shape[0]\n",
    "    print(f\"Missing timestamps count: {missing_timestamps_count}\")\n",
    "    if missing_timestamps_count > 0:\n",
    "        print(\"Example of missing timestamps:\")\n",
    "        print(df[df['timestamp'] == \"Unknown\"].head())\n",
    "\n",
    "# Example usage\n",
    "file_path = 'southampton_litter_with_OA&Population.csv'  # Replace with actual filename\n",
    "output_file = 'southampton_litter_with_OA-per-Population-based-year.csv'\n",
    "update_litter_analysis(file_path, output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polite_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
